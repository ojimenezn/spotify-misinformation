{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gh5l3V2DjHAg"
      },
      "outputs": [],
      "source": [
        "!pip install -U sentence-transformers\n",
        "!pip install transformers\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from transformers import BertModel, BertTokenizer\n",
        "\n",
        "# from google.colab import auth\n",
        "# auth.authenticate_user()\n",
        "\n",
        "# import gspread\n",
        "# from oauth2client.client import GoogleCredentials\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/drive')\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvA_qW1Qvcl9"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DvPz1yFzxFOH"
      },
      "outputs": [],
      "source": [
        "## Load manually labeled data\n",
        "# From colab-setup, replace if changes were made to this file\n",
        "# Initialize directories used\n",
        "\n",
        "parent_dir = '/drive/MyDrive/spotify-misinformation'\n",
        "\n",
        "modeling_output_dir = f\"{parent_dir}/modeling-output\"\n",
        "trained_models_output_dir = f\"{modeling_output_dir}/trained-models\"\n",
        "\n",
        "## Labeling outputs directories \n",
        "labeling_output_dir = f\"{parent_dir}/labeling-output\"\n",
        "labeled_dataset = f\"{labeling_output_dir}/manually-labeled-matched-pairs.csv\"\n",
        "\n",
        "labeled_data = pd.read_csv(labeled_dataset)\n",
        "\n",
        "# split data, load into dataset\n",
        "train_labeled_data, test_labeled_data = train_test_split(labeled_data, shuffle=True, train_size=0.8, random_state=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0KDSfEpdMny"
      },
      "source": [
        "# Focal Loss Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dt3TGi9ZdOqO"
      },
      "outputs": [],
      "source": [
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, weight=None, gamma=1):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        assert gamma >= 0\n",
        "        self.gamma = gamma\n",
        "        self.weight = weight\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        '''\n",
        "        :param input: input predictions\n",
        "        :param target: labels\n",
        "        :return: tensor of focal loss in scalar\n",
        "        '''\n",
        "        loss = None\n",
        "        # reference: https://github.com/kaidic/LDAM-DRW/blob/3193f05c1e6e8c4798c5419e97c5a479d991e3e9/losses.py#L13 \n",
        "        ce_loss = F.cross_entropy(input=input, target=target, weight=self.weight, reduction='none')\n",
        "        loss = ce_loss * (1 - torch.exp(-ce_loss)) ** self.gamma\n",
        "        loss = loss.mean()\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0L6P9HvYveLT"
      },
      "source": [
        "# SentenceBERT Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtkmoZmBnBhu"
      },
      "outputs": [],
      "source": [
        "class SBERTAggregationClassifier(nn.Module):\n",
        "  def __init__(self, input_size=384, output_size=6):\n",
        "    super().__init__()\n",
        "\n",
        "    self.aggregator = nn.Sequential(\n",
        "        nn.Linear(input_size * 2, input_size, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.5),\n",
        "        )\n",
        "    \n",
        "    self.classifier = nn.Sequential(\n",
        "          nn.Linear(input_size, input_size, bias=True),\n",
        "          nn.ReLU(),\n",
        "          nn.Dropout(0.5),\n",
        "          nn.Linear(input_size, output_size, bias=True),\n",
        "      )\n",
        "    \n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "    \n",
        "  def forward(self, fc_embed, pod_embed):\n",
        "    x = torch.cat((fc_embed, pod_embed), dim=1)\n",
        "\n",
        "    x = self.aggregator(x)\n",
        "    logits = self.classifier(x)\n",
        "    logits = self.softmax(logits)\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vWWX0rdvZNP"
      },
      "outputs": [],
      "source": [
        "class SBERTDataset(Dataset):\n",
        "    def __init__(self, labeled_data, sbert_model):\n",
        "      fc_claims = list(labeled_data['Fact Checked Claim'])\n",
        "\n",
        "      # strip podcast claims\n",
        "      pod_claims = [x.strip() for x in list(labeled_data['Podcast Claim'])]\n",
        "\n",
        "      self.claim_embeddings = [sbert_model.encode(x, convert_to_tensor=True) for x in fc_claims]\n",
        "      self.podcast_embeddings = [sbert_model.encode(x, convert_to_tensor=True) for x in pod_claims]\n",
        "\n",
        "      # cast labels to ints, subtract one (goest from 1-6 to 0-5, easier for argmax comparison)\n",
        "      self.labels = [int(x) - 1 for x in list(labeled_data['Stance Agreement'])]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.claim_embeddings)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.claim_embeddings[idx], self.podcast_embeddings[idx], self.labels[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IAmi4_zx0Uhj"
      },
      "outputs": [],
      "source": [
        "# Load sentenceBert model\n",
        "\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2', device=device)\n",
        "\n",
        "# Load train and test dataloaders\n",
        "\n",
        "train_dataset = SBERTDataset(labeled_data=train_labeled_data, sbert_model=model)\n",
        "test_dataset = SBERTDataset(labeled_data=test_labeled_data, sbert_model=model)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=4)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTBxITYI5XYK"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, roc_auc_score\n",
        "\n",
        "def compute_stats_sbert(model, dataloader, phase_str=\"\", log=True):\n",
        "  test_preds = []\n",
        "  test_truth = []\n",
        "  test_logits = []\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  ## test accuracy on test set\n",
        "  for claim_embeds, pod_embeds, labels in dataloader:\n",
        "      claim_embeds = claim_embeds.to(device)\n",
        "      pod_embeds = pod_embeds.to(device)\n",
        "      test_truth.append(labels.cpu().detach().numpy())\n",
        "\n",
        "      with torch.no_grad():\n",
        "        logits = model.forward(claim_embeds, pod_embeds) # (h1 = (10,100), h2 = (10,100))\n",
        "        test_logits.append(logits.cpu().detach().numpy())\n",
        "        preds = logits.argmax(dim=1)\n",
        "        test_preds.append(preds.cpu().detach().numpy())\n",
        "\n",
        "  test_preds = np.hstack(test_preds)\n",
        "  test_truth = np.hstack(test_truth)\n",
        "\n",
        "  test_logits = np.vstack(test_logits)\n",
        "  \n",
        "  test_truth_one_hot = np.zeros(test_logits.shape)\n",
        "  test_truth_one_hot[np.stack((np.arange(len(test_truth)))), test_truth] = 1\n",
        "\n",
        "  acc = accuracy_score(test_truth, test_preds)\n",
        "  auc = roc_auc_score(test_truth_one_hot, test_logits, average='weighted', multi_class='ovr')\n",
        "\n",
        "  if log:\n",
        "    print(f\"{phase_str}Accuracy: {acc}\")\n",
        "    # print(f\"{phase_str}F1 Score: {f1_score(test_truth, test_preds, average='weighted')}\")\n",
        "    # print(f\"{phase_str}Recall: {precision_score(test_truth, test_preds, average='weighted')}\")\n",
        "    # print(f\"{phase_str}Precision: {recall_score(test_truth, test_preds, average='weighted')}\")\n",
        "    print(f\"{phase_str}AUC Score: {auc}\")\n",
        "  \n",
        "  return acc, auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJNGLyuOpJyW"
      },
      "outputs": [],
      "source": [
        "#compute_stats_sbert(sb_classifier, test_dataloader, phase_str=f\"Epoch {epoch} Testing \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hx14WluT5BT2"
      },
      "outputs": [],
      "source": [
        "## Train linear classifier using sentenceBert embeddings\n",
        "\n",
        "sbert_model_name = \"sbert_linear.pth\"\n",
        "\n",
        "sb_lr = 0.00001\n",
        "sb_epochs = 1001\n",
        "\n",
        "sb_classifier = SBERTAggregationClassifier()\n",
        "sb_classifier = sb_classifier.to(device)\n",
        "sb_optimizier = torch.optim.Adam(sb_classifier.parameters(), lr=sb_lr)\n",
        "\n",
        "# sb_loss = nn.CrossEntropyLoss()\n",
        "sb_loss = FocalLoss(gamma=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hubWMnly4uRv"
      },
      "outputs": [],
      "source": [
        "# Train Classifier and save model that performs best on test dataset\n",
        "high_auc = 0\n",
        "high_acc = 0\n",
        "best_model_state_dict = None\n",
        "\n",
        "accuracies = []\n",
        "aucs = []\n",
        "\n",
        "for epoch in range(sb_epochs):\n",
        "  sb_classifier.train()\n",
        "\n",
        "  for claim_embeds, pod_embeds, labels in train_dataloader:\n",
        "    claim_embeds = claim_embeds.to(device)\n",
        "    pod_embeds = pod_embeds.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    sb_classifier.zero_grad()\n",
        "    \n",
        "    outputs = sb_classifier.forward(claim_embeds, pod_embeds) # (h1 = (10,100), h2 = (10,100))\n",
        "\n",
        "    # for focal loss\n",
        "    # outputs = outputs.argmax(dim=1)\n",
        "\n",
        "    loss = sb_loss(outputs, labels)\n",
        "    loss.backward()\n",
        "    sb_optimizier.step()\n",
        "    \n",
        "  acc, auc = compute_stats_sbert(sb_classifier, test_dataloader, log=False)\n",
        "\n",
        "  if auc > high_auc:\n",
        "    high_auc = auc\n",
        "    high_acc = acc\n",
        "    best_model_state_dict = sb_classifier.state_dict()\n",
        "\n",
        "  accuracies.append(acc)\n",
        "  aucs.append(auc)\n",
        "\n",
        "  if epoch % (sb_epochs // 10) == 0:\n",
        "    _,_ = compute_stats_sbert(sb_classifier, train_dataloader, phase_str=f\"Epoch {epoch} Training \")\n",
        "    _,_ = compute_stats_sbert(sb_classifier, test_dataloader, phase_str=f\"Epoch {epoch} Testing \")\n",
        "    print(f\"Epoch {epoch}, loss: {loss.item()}\")\n",
        "\n",
        "## Save best model after training\n",
        "torch.save(best_model_state_dict, f\"{trained_models_output_dir}/{sbert_model_name}\")\n",
        "print(f\"Best Model ROC AUC: {high_auc}\")\n",
        "print(f\"Best Model Accuracy: {high_acc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ozkUXyEgveyp"
      },
      "outputs": [],
      "source": [
        "print(max(accuracies))\n",
        "print(max(aucs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yxes8jHo6lpk"
      },
      "source": [
        "# Bert Embedding Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulzQd5io6qb9"
      },
      "outputs": [],
      "source": [
        "class BERTAggregationClassifier(nn.Module):\n",
        "  def __init__(self, bert_model, output_size=6):\n",
        "    super().__init__()\n",
        "\n",
        "    self.bert_model = bert_model\n",
        "\n",
        "    input_size = list(bert_model.modules())[-2].out_features\n",
        "\n",
        "    for param in self.bert_model.parameters():\n",
        "      param.requires_grad = False\n",
        "    \n",
        "    self.classifier = nn.Sequential(\n",
        "          nn.Linear(input_size, input_size // 2, bias=True),\n",
        "          nn.ReLU(),\n",
        "          nn.Dropout(0.5),\n",
        "          nn.Linear(input_size // 2, output_size, bias=True),\n",
        "      )\n",
        "    \n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "    \n",
        "  def forward(self, input_ids, token_type_ids, attention_mask):\n",
        "    embed = self.bert_model(input_ids, token_type_ids, attention_mask)[1]\n",
        "    logits = self.classifier(embed)\n",
        "    logits = self.softmax(logits)\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKFY4QTB7Qhc"
      },
      "outputs": [],
      "source": [
        "class BERTDataset(Dataset):\n",
        "    def __init__(self, labeled_data, bert_tokenizer, device='cuda'):\n",
        "      fc_claims = list(labeled_data['Fact Checked Claim'])\n",
        "\n",
        "      # strip podcast claims\n",
        "      pod_claims = [x.strip() for x in list(labeled_data['Podcast Claim'])]\n",
        "\n",
        "      self.embeddings = [tokenizer(x, y, return_tensors=\"pt\", max_length=400, padding='max_length') for x, y in zip(fc_claims, pod_claims)]\n",
        "\n",
        "      # cast labels to ints, subtract one (goest from 1-6 to 0-5, easier for argmax comparison)\n",
        "      self.labels = [int(x) - 1 for x in list(labeled_data['Stance Agreement'])]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.embeddings)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      # return self.embeddings[idx], self.labels[idx]\n",
        "      return self.embeddings[idx]['input_ids'].squeeze(), self.embeddings[idx]['token_type_ids'].squeeze(), self.embeddings[idx]['attention_mask'].squeeze(), self.labels[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hdSTBCjg7j3J"
      },
      "outputs": [],
      "source": [
        "# Load BERT model and tokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n",
        "model = BertModel.from_pretrained('bert-large-uncased')\n",
        "model = model.to(device)\n",
        "\n",
        "# split data, load into dataset\n",
        "train_dataset = BERTDataset(labeled_data=train_labeled_data, bert_tokenizer=tokenizer, device=device)\n",
        "test_dataset = BERTDataset(labeled_data=test_labeled_data, bert_tokenizer=tokenizer, device=device)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=4)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjLNHaWANlzE"
      },
      "outputs": [],
      "source": [
        "## Train linear classifier using sentenceBert embeddings\n",
        "\n",
        "bert_frozen_model_name = \"bert_frozen_linear.pth\"\n",
        "\n",
        "bert_lr = 0.0001\n",
        "bert_epochs = 11\n",
        "\n",
        "bert_classifier = BERTAggregationClassifier(bert_model=model)\n",
        "bert_classifier = bert_classifier.to(device)\n",
        "bert_optimizier = torch.optim.Adam(bert_classifier.parameters(), lr=bert_lr)\n",
        "\n",
        "# bert_loss = nn.CrossEntropyLoss()\n",
        "bert_loss = FocalLoss(gamma=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jowq1m8IdsV"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, roc_auc_score\n",
        "\n",
        "def compute_stats_bert(test_model, dataloader, phase_str=\"\", log=True):\n",
        "  test_preds = []\n",
        "  test_truth = []\n",
        "  test_logits = []\n",
        "\n",
        "  test_model.eval()\n",
        "\n",
        "  ## test accuracy on test set\n",
        "  for input_ids, token_type_ids, attention_mask, labels in dataloader:\n",
        "      input_ids = input_ids.to(device)\n",
        "      token_type_ids = token_type_ids.to(device)\n",
        "      attention_mask = attention_mask.to(device)\n",
        "      test_truth.append(labels.cpu().detach().numpy())\n",
        "\n",
        "      with torch.no_grad():\n",
        "        logits = test_model.forward(input_ids, token_type_ids, attention_mask) # (h1 = (10,100), h2 = (10,100))\n",
        "        test_logits.append(logits.cpu().detach().numpy())\n",
        "        preds = logits.argmax(dim=1)\n",
        "        test_preds.append(preds.cpu().detach().numpy())\n",
        "\n",
        "  test_preds = np.hstack(test_preds)\n",
        "  test_truth = np.hstack(test_truth)\n",
        "\n",
        "  test_logits = np.vstack(test_logits)\n",
        "  \n",
        "  test_truth_one_hot = np.zeros(test_logits.shape)\n",
        "  test_truth_one_hot[np.stack((np.arange(len(test_truth)))), test_truth] = 1\n",
        "\n",
        "  acc = accuracy_score(test_truth, test_preds)\n",
        "  auc = roc_auc_score(test_truth_one_hot, test_logits, average='weighted', multi_class='ovr')\n",
        "\n",
        "  if log:\n",
        "    print(f\"{phase_str}Accuracy: {acc}\")\n",
        "    # print(f\"{phase_str}F1 Score: {f1_score(test_truth, test_preds, average='weighted')}\")\n",
        "    # print(f\"{phase_str}Recall: {precision_score(test_truth, test_preds, average='weighted')}\")\n",
        "    # print(f\"{phase_str}Precision: {recall_score(test_truth, test_preds, average='weighted')}\")\n",
        "    print(f\"{phase_str}AUC Score: {auc}\")\n",
        "  \n",
        "  return acc, auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILIscBbfPoK7"
      },
      "outputs": [],
      "source": [
        "# Train Classifier\n",
        "high_auc = 0\n",
        "high_acc = 0\n",
        "best_model_state_dict = None\n",
        "\n",
        "accuracies = []\n",
        "aucs = []\n",
        "\n",
        "for epoch in range(bert_epochs):\n",
        "  bert_classifier.train()\n",
        "\n",
        "  for input_ids, token_type_ids, attention_mask, labels in train_dataloader:\n",
        "    input_ids = input_ids.to(device)\n",
        "    token_type_ids = token_type_ids.to(device)\n",
        "    attention_mask = attention_mask.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    bert_classifier.zero_grad()\n",
        "    \n",
        "    outputs = bert_classifier.forward(input_ids, token_type_ids, attention_mask)\n",
        "    loss = bert_loss(outputs, labels)\n",
        "    loss.backward()\n",
        "    bert_optimizier.step()\n",
        "\n",
        "  acc, auc = compute_stats_bert(bert_classifier, test_dataloader, log=False)\n",
        "\n",
        "  if auc > high_auc:\n",
        "    high_auc = auc\n",
        "    high_acc = acc\n",
        "    best_model_state_dict = bert_classifier.state_dict()\n",
        "\n",
        "  accuracies.append(acc)\n",
        "  aucs.append(auc)\n",
        "\n",
        "  if epoch % (bert_epochs // 10) == 0:\n",
        "    _,_ = compute_stats_bert(bert_classifier, train_dataloader, phase_str=f\"Epoch {epoch} Training \")\n",
        "    _,_ = compute_stats_bert(bert_classifier, test_dataloader, phase_str=f\"Epoch {epoch} Testing \")\n",
        "    print(f\"Epoch {epoch}, loss: {loss.item()}\")\n",
        "\n",
        "## Save best model after training\n",
        "torch.save(best_model_state_dict, f\"{trained_models_output_dir}/{bert_frozen_model_name}\")\n",
        "print(f\"Best Model ROC AUC: {high_auc}\")\n",
        "print(f\"Best Model Accuracy: {high_acc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CS31qcImJZCY"
      },
      "outputs": [],
      "source": [
        "print(max(accuracies))\n",
        "print(max(aucs))\n",
        "# compute_stats_bert(bert_classifier, test_dataloader, phase_str=f\"Epoch {epoch} Testing\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2OaUBJJ03dH"
      },
      "source": [
        "# Fine Tuning BERT Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3bpxff307MR"
      },
      "outputs": [],
      "source": [
        "class BERTFTAggregationClassifier(nn.Module):\n",
        "  def __init__(self, bert_model, output_size=6):\n",
        "    super().__init__()\n",
        "\n",
        "    self.bert_model = bert_model\n",
        "\n",
        "    input_size = list(bert_model.modules())[-2].out_features\n",
        "\n",
        "    # for param in self.bert_model.parameters():\n",
        "    #   param.requires_grad = False\n",
        "    \n",
        "    self.classifier = nn.Sequential(\n",
        "          nn.Linear(input_size, input_size // 2, bias=True),\n",
        "          nn.ReLU(),\n",
        "          nn.Dropout(0.5),\n",
        "          nn.Linear(input_size // 2, output_size, bias=True),\n",
        "      )\n",
        "    \n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "    \n",
        "  def forward(self, input_ids, token_type_ids, attention_mask):\n",
        "    embed = self.bert_model(input_ids, token_type_ids, attention_mask)[1]\n",
        "    logits = self.classifier(embed)\n",
        "    logits = self.softmax(logits)\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3XNpv8G1mWr"
      },
      "outputs": [],
      "source": [
        "class BERTDataset(Dataset):\n",
        "    def __init__(self, labeled_data, bert_tokenizer, device='cuda'):\n",
        "      fc_claims = list(labeled_data['Fact Checked Claim'])\n",
        "\n",
        "      # strip podcast claims\n",
        "      pod_claims = [x.strip() for x in list(labeled_data['Podcast Claim'])]\n",
        "\n",
        "      self.embeddings = [tokenizer(x, y, return_tensors=\"pt\", max_length=400, padding='max_length') for x, y in zip(fc_claims, pod_claims)]\n",
        "\n",
        "      # cast labels to ints, subtract one (goest from 1-6 to 0-5, easier for argmax comparison)\n",
        "      self.labels = [int(x) - 1 for x in list(labeled_data['Stance Agreement'])]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.embeddings)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      # return self.embeddings[idx], self.labels[idx]\n",
        "      return self.embeddings[idx]['input_ids'].squeeze(), self.embeddings[idx]['token_type_ids'].squeeze(), self.embeddings[idx]['attention_mask'].squeeze(), self.labels[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXdTyNUZ1muf"
      },
      "outputs": [],
      "source": [
        "# Load BERT model and tokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n",
        "model = BertModel.from_pretrained('bert-large-uncased')\n",
        "model = model.to(device)\n",
        "\n",
        "# split data, load into dataset\n",
        "train_dataset = BERTDataset(labeled_data=train_labeled_data, bert_tokenizer=tokenizer, device=device)\n",
        "test_dataset = BERTDataset(labeled_data=test_labeled_data, bert_tokenizer=tokenizer, device=device)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=4)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qKMyFbx10s_"
      },
      "outputs": [],
      "source": [
        "## Train linear classifier using sentenceBert embeddings\n",
        "\n",
        "bert_ft_frozen_model_name = \"bert_finetuned_linear.pth\"\n",
        "\n",
        "bert_ft_lr = 0.0001\n",
        "bert_ft_epochs = 11\n",
        "\n",
        "bert_ft_classifier = BERTFTAggregationClassifier(bert_model=model)\n",
        "bert_ft_classifier = bert_ft_classifier.to(device)\n",
        "bert_ft_optimizier = torch.optim.Adam(bert_ft_classifier.parameters(), lr=bert_ft_lr)\n",
        "\n",
        "# bert_loss = nn.CrossEntropyLoss()\n",
        "bert_ft_loss = FocalLoss(gamma=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUppEFbp2XJb"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, roc_auc_score\n",
        "\n",
        "def compute_stats_bert(test_model, dataloader, phase_str=\"\", log=True):\n",
        "  test_preds = []\n",
        "  test_truth = []\n",
        "  test_logits = []\n",
        "\n",
        "  test_model.eval()\n",
        "\n",
        "  ## test accuracy on test set\n",
        "  for input_ids, token_type_ids, attention_mask, labels in dataloader:\n",
        "      input_ids = input_ids.to(device)\n",
        "      token_type_ids = token_type_ids.to(device)\n",
        "      attention_mask = attention_mask.to(device)\n",
        "      test_truth.append(labels.cpu().detach().numpy())\n",
        "\n",
        "      with torch.no_grad():\n",
        "        logits = test_model.forward(input_ids, token_type_ids, attention_mask) # (h1 = (10,100), h2 = (10,100))\n",
        "        test_logits.append(logits.cpu().detach().numpy())\n",
        "        preds = logits.argmax(dim=1)\n",
        "        test_preds.append(preds.cpu().detach().numpy())\n",
        "\n",
        "  test_preds = np.hstack(test_preds)\n",
        "  test_truth = np.hstack(test_truth)\n",
        "\n",
        "  test_logits = np.vstack(test_logits)\n",
        "  \n",
        "  test_truth_one_hot = np.zeros(test_logits.shape)\n",
        "  test_truth_one_hot[np.stack((np.arange(len(test_truth)))), test_truth] = 1\n",
        "\n",
        "  acc = accuracy_score(test_truth, test_preds)\n",
        "  auc = roc_auc_score(test_truth_one_hot, test_logits, average='weighted', multi_class='ovr')\n",
        "\n",
        "  if log:\n",
        "    print(f\"{phase_str}Accuracy: {acc}\")\n",
        "    # print(f\"{phase_str}F1 Score: {f1_score(test_truth, test_preds, average='weighted')}\")\n",
        "    # print(f\"{phase_str}Recall: {precision_score(test_truth, test_preds, average='weighted')}\")\n",
        "    # print(f\"{phase_str}Precision: {recall_score(test_truth, test_preds, average='weighted')}\")\n",
        "    print(f\"{phase_str}AUC Score: {auc}\")\n",
        "  \n",
        "  return acc, auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYXXgbjF2YkB"
      },
      "outputs": [],
      "source": [
        "# Train Classifier\n",
        "high_auc = 0\n",
        "high_acc = 0\n",
        "best_model_state_dict = None\n",
        "\n",
        "accuracies = []\n",
        "aucs = []\n",
        "\n",
        "for epoch in range(bert_ft_epochs):\n",
        "  bert_ft_classifier.train()\n",
        "\n",
        "  for input_ids, token_type_ids, attention_mask, labels in train_dataloader:\n",
        "    input_ids = input_ids.to(device)\n",
        "    token_type_ids = token_type_ids.to(device)\n",
        "    attention_mask = attention_mask.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    bert_ft_classifier.zero_grad()\n",
        "    \n",
        "    outputs = bert_ft_classifier.forward(input_ids, token_type_ids, attention_mask)\n",
        "    loss = bert_ft_loss(outputs, labels)\n",
        "    loss.backward()\n",
        "    bert_ft_optimizier.step()\n",
        "\n",
        "  acc, auc = compute_stats_bert(bert_ft_classifier, test_dataloader, log=False)\n",
        "\n",
        "  if auc > high_auc:\n",
        "    high_auc = auc\n",
        "    high_acc = acc\n",
        "    best_model_state_dict = bert_ft_classifier.state_dict()\n",
        "\n",
        "  accuracies.append(acc)\n",
        "  aucs.append(auc)\n",
        "\n",
        "  if epoch % (bert_ft_epochs // 10) == 0:\n",
        "    _,_ = compute_stats_bert(bert_ft_classifier, train_dataloader, phase_str=f\"Epoch {epoch} Training \")\n",
        "    _,_ = compute_stats_bert(bert_ft_classifier, test_dataloader, phase_str=f\"Epoch {epoch} Testing \")\n",
        "    print(f\"Epoch {epoch}, loss: {loss.item()}\")\n",
        "\n",
        "## Save best model after training\n",
        "torch.save(best_model_state_dict, f\"{trained_models_output_dir}/{bert_ft_frozen_model_name}\")\n",
        "print(f\"Best Model ROC AUC: {high_auc}\")\n",
        "print(f\"Best Model Accuracy: {high_acc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WKBJxfau4VeK"
      },
      "outputs": [],
      "source": [
        "print(max(accuracies))\n",
        "print(max(aucs))\n",
        "compute_stats_bert(bert_ft_classifier, test_dataloader, phase_str=f\"Epoch {epoch} Testing\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9evj2d1otKD"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "model-training",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}