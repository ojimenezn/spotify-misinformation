{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQCTp_R9yeaC"
      },
      "outputs": [],
      "source": [
        "!pip install -U sentence-transformers\n",
        "# !pip install transformers\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/drive')\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEo7nz-4y_qM"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPvkL7rfzh3I"
      },
      "outputs": [],
      "source": [
        "class PodcastClaims: \n",
        "\n",
        "\tdef __init__(self, show_uri, episode_uri, transcript_claims, index):\n",
        "\t\tself.show_uri = show_uri\n",
        "\t\tself.episode_uri = episode_uri\n",
        "\t\tself.center_claim = transcript_claims[len(transcript_claims) // 2]\n",
        "\t\tself.context_claim = \".\".join(transcript_claims)\n",
        "\t\tself.index = index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mo0z5gb5y0Lj"
      },
      "outputs": [],
      "source": [
        "## Load manually labeled data\n",
        "# From colab-setup, replace if changes were made to this file\n",
        "# Initialize directories used\n",
        "\n",
        "parent_dir = '/drive/MyDrive/spotify-misinformation'\n",
        "\n",
        "# Model output directories\n",
        "\n",
        "modeling_output_dir = f\"{parent_dir}/modeling-output\"\n",
        "trained_models_output_dir = f\"{modeling_output_dir}/trained-models\"\n",
        "\n",
        "# Define file paths for where podcast claims and fact checked claims are located\n",
        "\n",
        "preprocessing_output_dir = f\"{parent_dir}/preprocessing-output\"\n",
        "matched_claims_output_dir = f\"{parent_dir}/matched-claims-output\"\n",
        "\n",
        "fact_checked_claims_fp = f\"{preprocessing_output_dir}/politifact_filtered.csv\"\n",
        "transcript_claims_fp = f\"{preprocessing_output_dir}/podcast_claims_context_2.tsv\"\n",
        "\n",
        "# Define filepath for matched claims\n",
        "\n",
        "matched_claims_fp = f\"{matched_claims_output_dir}/matched_claims_context_2.txt\"\n",
        "\n",
        "# Define filepath for predicted labels\n",
        "\n",
        "predicted_mc_fp = f\"{modeling_output_dir}/only_predicted_label_predicted_mc_context_2.txt\"\n",
        "predicted_mc_veracity_fp = f\"{modeling_output_dir}/predicted_mc_context_2.txt\"\n",
        "\n",
        "# utility functions to read data\n",
        "\n",
        "claims_df = pd.read_csv(fact_checked_claims_fp)\n",
        "pc_claims = []\n",
        "\n",
        "with open(transcript_claims_fp, 'r') as all_transcripts:\n",
        "  for idx, line in enumerate(all_transcripts):\n",
        "    # split_line = line.strip().split(\"\\t\")\n",
        "    pc_claims.append(line.strip().split(\"\\t\"))\n",
        "\n",
        "def get_kb_claim(kb_idx):\n",
        "  return claims_df['Statement'][int(kb_idx)]\n",
        "\n",
        "def get_pc_claim(pc_idx):\n",
        "  return \".\".join(pc_claims[int(pc_idx)][2:])\n",
        "\n",
        "def get_kb_claim_date(kb_idx):\n",
        "  return claims_df['Date'][int(kb_idx)]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns = ['Fact Checked Claim Index', 'Podcast Claim Index', 'Cosine Similarity Score']\n",
        "mc_df = pd.read_csv(matched_claims_fp, names = columns)\n",
        "# mc_df = mc_df.sort_values(by=['Cosine Similarity Score'], ascending=False)[3000:]\n",
        "mc_df = mc_df.sort_values(by=['Cosine Similarity Score'], ascending=False)"
      ],
      "metadata": {
        "id": "Lg8IRcH3IN5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SentenceBERT"
      ],
      "metadata": {
        "id": "uK5DWKzKCoLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SBERTAggregationClassifier(nn.Module):\n",
        "  def __init__(self, input_size=384, output_size=6):\n",
        "    super().__init__()\n",
        "\n",
        "    self.aggregator = nn.Sequential(\n",
        "        nn.Linear(input_size * 2, input_size, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.5),\n",
        "        )\n",
        "    \n",
        "    self.classifier = nn.Sequential(\n",
        "          nn.Linear(input_size, input_size, bias=True),\n",
        "          nn.ReLU(),\n",
        "          nn.Dropout(0.5),\n",
        "          nn.Linear(input_size, output_size, bias=True),\n",
        "      )\n",
        "    \n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "    \n",
        "  def forward(self, fc_embed, pod_embed):\n",
        "    x = torch.cat((fc_embed, pod_embed), dim=1)\n",
        "\n",
        "    x = self.aggregator(x)\n",
        "    logits = self.classifier(x)\n",
        "    logits = self.softmax(logits)\n",
        "    return logits"
      ],
      "metadata": {
        "id": "t0W3bE3kCqc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SBERTPredictionDataset(Dataset):\n",
        "    def __init__(self, kb_claims, podcast_claims, sbert_model):\n",
        "      self.claim_embeddings = sbert_model.encode(kb_claims, convert_to_tensor=True)\n",
        "      self.podcast_embeddings = sbert_model.encode(podcast_claims, convert_to_tensor=True)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.claim_embeddings)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.claim_embeddings[idx], self.podcast_embeddings[idx]"
      ],
      "metadata": {
        "id": "C4vlC_6DC2gF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predictions(model, dataloader):\n",
        "  test_preds = []\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  ## test accuracy on test set\n",
        "  for claim_embeds, pod_embeds in dataloader:\n",
        "      claim_embeds = claim_embeds.to(device)\n",
        "      pod_embeds = pod_embeds.to(device)\n",
        "\n",
        "      with torch.no_grad():\n",
        "        logits = model.forward(claim_embeds, pod_embeds) # (h1 = (10,100), h2 = (10,100))\n",
        "        preds = logits.argmax(dim=1)\n",
        "        test_preds.append(preds.cpu().detach().numpy())\n",
        "\n",
        "  return list(np.hstack(test_preds))"
      ],
      "metadata": {
        "id": "V1EI3PJc0Z7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentenceTransformer('all-MiniLM-L6-v2', device=device)\n",
        "\n",
        "sbert_model_name = \"sbert_linear.pth\"\n",
        "\n",
        "sb_classifier = SBERTAggregationClassifier()\n",
        "sb_classifier.load_state_dict(torch.load(f\"{trained_models_output_dir}/{sbert_model_name}\"))\n",
        "sb_classifier = sb_classifier.to(device)\n",
        "sb_classifier.eval()"
      ],
      "metadata": {
        "id": "hIax8laxy14k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Uncomment if runtime disconnects\n",
        "\n",
        "# count = 0\n",
        "\n",
        "# with open(predicted_mc_fp, 'r') as matched_claims_predicted:\n",
        "#   for line in matched_claims_predicted:\n",
        "#     count += 1\n",
        "\n",
        "# print(count)\n"
      ],
      "metadata": {
        "id": "h_rqk6hJ3r7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# randomly sample \n",
        "mc_df = mc_df.sample(frac=0.5, random_state=11)\n",
        "print(len(mc_df))"
      ],
      "metadata": {
        "id": "z4ZpX8BxlvTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 40000\n",
        "start_time = time.time()\n",
        "\n",
        "with open(predicted_mc_fp, 'a') as matched_claims_predicted:\n",
        "\n",
        "  mc_rows = []\n",
        "\n",
        "  for idx, row in enumerate(mc_df.iloc):\n",
        "\n",
        "    # used for when runtime stops\n",
        "      # remember to change file open to append instead of write\n",
        "      # if idx <= 12450000:\n",
        "      #   continue\n",
        "\n",
        "    mc_rows.append(row)\n",
        "\n",
        "    if idx % batch_size == 0 and idx != 0:\n",
        "      kb_claims = [claims_df['Statement'][int(x['Fact Checked Claim Index'])] for x in mc_rows]\n",
        "      podcast_claims = [\".\".join(pc_claims[int(x['Podcast Claim Index'])]) for x in mc_rows]\n",
        "\n",
        "      pred_dataset = SBERTPredictionDataset(kb_claims, podcast_claims, sbert_model=model)\n",
        "      pred_dataloader = DataLoader(pred_dataset, batch_size=4096)\n",
        "\n",
        "      preds = get_predictions(sb_classifier, pred_dataloader)\n",
        "\n",
        "      for row, pred in zip(mc_rows, preds):\n",
        "        matched_claims_predicted.write(f\"{int(row['Fact Checked Claim Index'])}, {int(row['Podcast Claim Index'])}, {row['Cosine Similarity Score']}, {pred}\\n\")\n",
        "\n",
        "      mc_rows = []\n",
        "\n",
        "      print(idx, time.time() - start_time)\n",
        "\n",
        "  ## Run for the last incomplete batch\n",
        "\n",
        "  kb_claims = [claims_df['Statement'][int(x['Fact Checked Claim Index'])] for x in mc_rows]\n",
        "  podcast_claims = [\".\".join(pc_claims[int(x['Podcast Claim Index'])]) for x in mc_rows]\n",
        "\n",
        "  pred_dataset = SBERTPredictionDataset(kb_claims, podcast_claims, sbert_model=model)\n",
        "  pred_dataloader = DataLoader(pred_dataset, batch_size=4096)\n",
        "\n",
        "  preds = get_predictions(sb_classifier, pred_dataloader)\n",
        "\n",
        "  for row, pred in zip(mc_rows, preds):\n",
        "    matched_claims_predicted.write(f\"{int(row['Fact Checked Claim Index'])}, {int(row['Podcast Claim Index'])}, {row['Cosine Similarity Score']}, {pred}\\n\")\n",
        "\n",
        "  mc_rows = []\n",
        "\n",
        "  print(idx, time.time() - start_time)"
      ],
      "metadata": {
        "id": "jcTWkmCQFKm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adding ground truth label and misinformation label"
      ],
      "metadata": {
        "id": "aF01OR9gjH2Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FINE-GRAINED MAPPING\n",
        "\n",
        "#Create a list of the values we want to assign for each condition\n",
        "true_mapping = ['True', 'Potentially True', 'Misinformation', \n",
        "                'Potential Misinformation', 'Unrelated', 'Inconclusive']\n",
        "mostly_true_mapping = ['True', 'Potentially True', 'Misinformation', \n",
        "                       'Potential Misinformation', 'Unrelated', 'Inconclusive']\n",
        "# HALF-TRUE LABELS ARE TRICKY \n",
        "half_true_mapping = ['Misinformation', 'Potential Misinformation', 'Potential Misinformation', \n",
        "                      'Potential Misinformation', 'Unrelated', 'Inconclusive']\n",
        "# Barely true and mostly false can be the same\n",
        "barely_true_mapping = ['Misinformation', 'Potential Misinformation', 'True', \n",
        "                      'Potentially True', 'Unrelated', 'Inconclusive']                     \n",
        "mostly_false_mapping = ['Misinformation', 'Potential Misinformation', 'True', \n",
        "                      'Potentially True', 'Unrelated', 'Inconclusive']\n",
        "false_mapping = ['Misinformation', 'Potential Misinformation', 'True', \n",
        "                 'Potentially True', 'Unrelated', 'Inconclusive']\n",
        "pants_fire_mapping = ['Misinformation', 'Potential Misinformation', 'True', \n",
        "                 'Potentially True', 'Unrelated', 'Inconclusive']\n",
        "\n",
        "# Add lists for final mapping\n",
        "mappings = [true_mapping, mostly_true_mapping, half_true_mapping, barely_true_mapping, mostly_false_mapping, false_mapping, pants_fire_mapping]\n",
        "\n",
        "# Create dictionary for mapping politifact labels to mapping list index\n",
        "claim_indexing = {\n",
        "    'true':0,\n",
        "    'mostly-true':1,\n",
        "    'half-true':2,\n",
        "    'barely-true':3,\n",
        "    'mostly-false':4,\n",
        "    'false':5,\n",
        "    'pants-fire':6,\n",
        "    }"
      ],
      "metadata": {
        "id": "F7RSqlI2jLSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "claims_df['Label'].value_counts()"
      ],
      "metadata": {
        "id": "kPIM4y-emNro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(predicted_mc_fp, 'r') as matched_claims_predicted:\n",
        "\n",
        "  with open(predicted_mc_veracity_fp, 'w') as mc_veracity:\n",
        "\n",
        "    for line in matched_claims_predicted:\n",
        "      t = line.strip().split(',')\n",
        "      print(t)\n",
        "      prediction = int(float(t[3]))\n",
        "      kb_label = claims_df['Label'][int(float(t[0]))]\n",
        "      misinformation_label = mappings[claim_indexing[kb_label]][prediction]\n",
        "\n",
        "      mc_veracity.write(f\"{t[0]}, {t[1]}, {t[2]}, {t[3]}, {kb_label}, {misinformation_label}\\n\")"
      ],
      "metadata": {
        "id": "W5YruIGK8lCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "i7-B7o1HrO59"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "sbert_model_prediction.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}