{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "labeling",
      "provenance": [],
      "collapsed_sections": [
        "hmd3B4X7lPW5",
        "-b0wKv4Am0_x"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwjPegLKyH7X",
        "outputId": "2dea6a77-731b-4e89-de85-613ec0d68c9f"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUzKxmoQyWx6"
      },
      "source": [
        "## From colab-setup, replace if changes were made to this file\n",
        "\n",
        "parent_dir = '/drive/MyDrive/spotify-misinformation'\n",
        "\n",
        "preprocessing_output_dir = f\"{parent_dir}/preprocessing-output\"\n",
        "matched_claims_output_dir = f\"{parent_dir}/matched-claims-output\"\n",
        "\n",
        "# Define file paths for where podcast claims and fact checked claims are located\n",
        "\n",
        "fact_checked_claims_fp = f\"{preprocessing_output_dir}/politifact_filtered.csv\"\n",
        "transcript_claims_fp = f\"{preprocessing_output_dir}/podcast_claims_context_2.tsv\"\n",
        "\n",
        "# Define filepath for matched claims\n",
        "\n",
        "matched_claims_fp = f\"{matched_claims_output_dir}/matched_claims_context_2.txt\"\n",
        "\n",
        "\n",
        "## Labeling outputs\n",
        "\n",
        "labeling_output_dir = f\"{parent_dir}/labeling-output\"\n",
        "blank_manually_labeled_datasets_dir = f\"{labeling_output_dir}/blank-manual-labeling-output\""
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5Jos12y7kBM"
      },
      "source": [
        "# Read data\n",
        "## Recommend using 'High-RAM' and 'GPU' runtime\n",
        "\n",
        "claims_df = pd.read_csv(fact_checked_claims_fp)\n",
        "\n",
        "with open(transcript_claims_fp, 'r') as f:\n",
        "  temp = f.readlines()\n",
        "  pc_claims = [\".\".join(line.split(\"\\t\")[2:]) for line in temp]\n",
        "  # print(pc_claims[0])\n",
        "\n",
        "def get_kb_claim(kb_idx):\n",
        "  return claims_df['Statement'][int(kb_idx)]\n",
        "\n",
        "def get_pc_claim(pc_idx):\n",
        "  return pc_claims[int(pc_idx)]\n",
        "\n",
        "def get_kb_claim_date(kb_idx):\n",
        "  return claims_df['Date'][int(kb_idx)]\n",
        "\n",
        "## Read matched claims dataset\n",
        "columns = ['Fact Checked Claim Index', 'Podcast Claim Index', 'Cosine Similarity Score']\n",
        "mc_df = pd.read_csv(matched_claims_fp, names = columns)\n",
        "\n",
        "# Find top 3000 paired claims ranked by cosine similarity score\n",
        "sorted_mc_df = mc_df.sort_values(by=['Cosine Similarity Score'], ascending=False)[:3000]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Print matched claims cosine similarity statistics\n",
        "\n",
        "print(len(mc_df))\n",
        "print(mc_df['Cosine Similarity Score'].max())\n",
        "print(mc_df['Cosine Similarity Score'].mean())\n",
        "print(mc_df['Cosine Similarity Score'].min())\n",
        "print(mc_df['Cosine Similarity Score'].std())\n",
        "print(mc_df['Cosine Similarity Score'].mode())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwEqIHyfJIvr",
        "outputId": "8dbaa3ee-6f9b-4ccf-cc36-095f66b9b748"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20\n",
            "0.4015714228153229\n",
            "0.22909172102808953\n",
            "0.20195361971855166\n",
            "0.042990087505111525\n",
            "0     0.201954\n",
            "1     0.202215\n",
            "2     0.203250\n",
            "3     0.206484\n",
            "4     0.207729\n",
            "5     0.208423\n",
            "6     0.212744\n",
            "7     0.212927\n",
            "8     0.213876\n",
            "9     0.215912\n",
            "10    0.218087\n",
            "11    0.224139\n",
            "12    0.227115\n",
            "13    0.228180\n",
            "14    0.230161\n",
            "15    0.235457\n",
            "16    0.238248\n",
            "17    0.243855\n",
            "18    0.249506\n",
            "19    0.401571\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmd3B4X7lPW5"
      },
      "source": [
        "# Getting dataset statistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1Dxsp6Bx66J",
        "outputId": "65fb1f77-1e63-48b8-a0ce-76048e7b2481"
      },
      "source": [
        "claims_df = pd.read_csv(fact_checked_claims_fp)\n",
        "\n",
        "words = []\n",
        "\n",
        "for x in claims_df['Statement'].tolist():\n",
        "  words += x.split(\" \")\n",
        "\n",
        "print(len(words))\n",
        "print(len(set(words)))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "484\n",
            "345\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzNcO5540Igo",
        "outputId": "4eec04a1-994b-45c2-da53-b5a15fcc990c"
      },
      "source": [
        "word_avg = [len(x.split(\" \")) for x in claims_df['Statement'].tolist()]\n",
        "print(sum(word_avg) / len(word_avg))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16.133333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYAVXyDu0yvv",
        "outputId": "374c278b-adab-4c51-e0b3-4d48c7fed93e"
      },
      "source": [
        "claims_df.iloc[len(claims_df) - 1]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Statement    Says Vice President Kamala Harris called the u...\n",
              "Link         https://www.politifact.com/factchecks/2021/dec...\n",
              "Date                                             ember 8, 2021\n",
              "Source                                         Instagram posts\n",
              "Label                                               pants-fire\n",
              "Name: 29, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQbu-SLszdti",
        "outputId": "afa3c821-0355-4bfd-8b85-5a9cc6dc003a"
      },
      "source": [
        "\n",
        "with open(transcript_claims_fp, 'r') as f:\n",
        "  temp = f.readlines()\n",
        "  pc_claims = [\",\".join(line.split(\",\")[2:]) for line in temp]\n",
        "\n",
        "print(len(pc_claims))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4fA_yQa1tBx",
        "outputId": "c66dd4dd-5d03-46a7-9007-29724dcd27db"
      },
      "source": [
        "w = set()\n",
        "for x in pc_claims:\n",
        "  for y in x.split(\" \"):\n",
        "    w.add(y)\n",
        "\n",
        "print(len(w))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "185\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ih32uMqUmSJs"
      },
      "source": [
        "# Finding top matches and saving for manual labeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "7CQL6tS63oPE",
        "outputId": "d0bab9ef-3660-4ca0-8336-5cf23ca16ef6"
      },
      "source": [
        "# print(int(sorted_mc_df.iloc[0]['Fact Checked Claim Index']))\n",
        "# print(int(sorted_mc_df.iloc[0]['Podcast Claim Index']))\n",
        "\n",
        "column_names = ['Fact Checked Claim Index', 'Podcast Claim Index', 'Fact Checked Claim', 'Podcast Claim']\n",
        "labeling_mc = []\n",
        "\n",
        "for row in sorted_mc_df.iloc:\n",
        "  kb_index = int(row['Fact Checked Claim Index'])\n",
        "  pc_index = int(row['Podcast Claim Index'])\n",
        "\n",
        "  kb_claim = get_kb_claim(kb_index)\n",
        "  pc_claim = get_pc_claim(pc_index)\n",
        "\n",
        "  labeling_mc.append([kb_index, pc_index, kb_claim, pc_claim])\n",
        "\n",
        "labeling_mc_df = pd.DataFrame(labeling_mc, columns=column_names)\n",
        "labeling_mc_df.head()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fact Checked Claim Index</th>\n",
              "      <th>Podcast Claim Index</th>\n",
              "      <th>Fact Checked Claim</th>\n",
              "      <th>Podcast Claim</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15</td>\n",
              "      <td>21</td>\n",
              "      <td>\"Canada joins the no jab, no food trend\"</td>\n",
              "      <td>I ain't gonna wait for the Mauri Mauri on me,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>27</td>\n",
              "      <td>“Ivanka Trump is joining the Democrats to run ...</td>\n",
              "      <td>Eh, eh, she cannot suck on my dick. Hey, I'ma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "      <td>“An organ recovery medical team pays tribute t...</td>\n",
              "      <td>SEP. yeah, I'm going to put it back in the sid...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14</td>\n",
              "      <td>27</td>\n",
              "      <td>“Hillary replaces Kamala Harris.”</td>\n",
              "      <td>Eh, eh, she cannot suck on my dick. Hey, I'ma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>21</td>\n",
              "      <td>At Lions Gate Hospital in Vancouver, “13 babie...</td>\n",
              "      <td>I ain't gonna wait for the Mauri Mauri on me,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Fact Checked Claim Index  ...                                      Podcast Claim\n",
              "0                        15  ...   I ain't gonna wait for the Mauri Mauri on me,...\n",
              "1                         5  ...   Eh, eh, she cannot suck on my dick. Hey, I'ma...\n",
              "2                        21  ...  SEP. yeah, I'm going to put it back in the sid...\n",
              "3                        14  ...   Eh, eh, she cannot suck on my dick. Hey, I'ma...\n",
              "4                         6  ...   I ain't gonna wait for the Mauri Mauri on me,...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enOf8BS966V7"
      },
      "source": [
        "labeling_mc_df['Stance Agreement'] = -1"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZ5iislYtzzo"
      },
      "source": [
        "random_df = labeling_mc_df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "labeling_phase = 'top_3000_context_2_single_sentence_'\n",
        "labeling_dir = f\"{blank_manually_labeled_datasets_dir}/{labeling_phase}\"\n",
        "\n",
        "overlap_df = random_df[0:600]\n",
        "overlap_df.to_csv(labeling_dir + 'omar_overlap.csv', index=False)\n",
        "overlap_df.to_csv(labeling_dir + 'abhijeet_overlap.csv', index=False)\n",
        "overlap_df.to_csv(labeling_dir + 'jon_overlap.csv', index=False)\n",
        "\n",
        "jon_df = random_df[600:1400]\n",
        "jon_df.to_csv(labeling_dir + 'jon_individual.csv', index=False)\n",
        "\n",
        "omar_df = random_df[1400:2200]\n",
        "omar_df.to_csv(labeling_dir + 'omar_individual.csv', index=False)\n",
        "\n",
        "ahibjeet_df = random_df[2200:]\n",
        "ahibjeet_df.to_csv(labeling_dir + 'abhijeet_individual.csv', index=False)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Interrater Scoring"
      ],
      "metadata": {
        "id": "lAvLY5FYKapy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import gspread\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "from nltk.metrics.agreement import AnnotationTask\n",
        "from google.colab import drive\n",
        "drive.mount('/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmN4Y7DSKcn8",
        "outputId": "b66010c1-5ac0-4290-8183-b5c0d2eec468"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /drive; to attempt to forcibly remount, call drive.mount(\"/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Assumes that the manually labeled data is a Google Spreadsheet \n",
        "## (after clicking 'Open in Sheets' for the csv and manually changing stance agreement to our manual label)\n",
        "\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())\n",
        "\n",
        "def df_from_google_sheets(path, columns):\n",
        "\n",
        "  worksheet = gc.open(path).sheet1\n",
        "\n",
        "  rows = worksheet.get_all_values()\n",
        "\n",
        "  rows = [x[:5] for x in rows]\n",
        "\n",
        "  return pd.DataFrame.from_records(rows[1:], columns=columns)"
      ],
      "metadata": {
        "id": "9Y7JMHrlKhLs"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scoring"
      ],
      "metadata": {
        "id": "JmeCwdgoK9OP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Reads overlap files of manually labeled data\n",
        "\n",
        "parent_dir = '/drive/MyDrive/spotify-misinformation'\n",
        "labeling_output_dir = f\"{parent_dir}/labeling-output\"\n",
        "blank_manually_labeled_datasets_dir = f\"{labeling_output_dir}/blank-manual-labeling-output\"\n",
        "\n",
        "labeling_phase = 'top_3000_context_2_single_sentence_'\n",
        "labeling_dir = f\"{blank_manually_labeled_datasets_dir}/{labeling_phase}\"\n",
        "\n",
        "column_names = ['Fact Checked Claim Index', 'Podcast Claim Index', 'Fact Checked Claim', 'Podcast Claim', 'Stance Agreement']\n",
        "\n",
        "jon_overlap = df_from_google_sheets(labeling_phase + 'jon_overlap', columns=column_names)\n",
        "omar_overlap = df_from_google_sheets(labeling_phase + 'omar_overlap', columns=column_names)\n",
        "ahibjeet_overlap = df_from_google_sheets(labeling_phase + 'abhijeet_overlap', columns=column_names)\n",
        "\n",
        "# get first k rows that we've labeled so far\n",
        "\n",
        "jo_200 = jon_overlap['Stance Agreement'][:600]\n",
        "oo_200 = omar_overlap['Stance Agreement'][:600]\n",
        "ao_200 = ahibjeet_overlap['Stance Agreement'][:600]\n",
        "\n",
        "val = '1'\n",
        "avg_agree_count = (np.sum(jo_200 == val) + np.sum(oo_200 == val) + np.sum(ao_200 == val)) / 3\n",
        "print('Avg agree count', avg_agree_count)\n",
        "\n",
        "val = '2'\n",
        "avg_disagree_count = (np.sum(jo_200 == val) + np.sum(oo_200 == val) + np.sum(ao_200 == val)) / 3\n",
        "print('Avg disagree count', avg_disagree_count)\n",
        "\n",
        "val = '3'\n",
        "avg_unrelated_count = (np.sum(jo_200 == val) + np.sum(oo_200 == val) + np.sum(ao_200 == val)) / 3\n",
        "print('Avg unrelated count', avg_unrelated_count)\n",
        "\n",
        "data = []\n",
        "data += [('Jon', idx, x) for idx, x in enumerate(jo_200)]\n",
        "data += [('Omar', idx, x) for idx, x in enumerate(oo_200)]\n",
        "data += [('Abhijeet', idx, x) for idx, x in enumerate(ao_200)]\n",
        "\n",
        "task = AnnotationTask(data=data)\n",
        "\n",
        "print('Kappa score', task.kappa())\n",
        "print('Multi Kappa score', task.multi_kappa())\n",
        "print('Krippendorf Alpha', task.alpha())"
      ],
      "metadata": {
        "id": "bIYplpr-K9-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Scores between Jon and Omar')\n",
        "data = []\n",
        "data += [('Jon', idx, x) for idx, x in enumerate(jo_200)]\n",
        "data += [('Omar', idx, x) for idx, x in enumerate(oo_200)]\n",
        "\n",
        "task = AnnotationTask(data=data)\n",
        "\n",
        "print('Observed Agreement', task.Ao('Jon', 'Omar'))\n",
        "print('Kappa score', task.kappa())\n",
        "print('Multi Kappa score', task.multi_kappa())\n",
        "print('Krippendorf Alpha', task.alpha())"
      ],
      "metadata": {
        "id": "2CsfQNC5LX-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Scores between Jon and Ahbijeet')\n",
        "data = []\n",
        "data += [('Jon', idx, x) for idx, x in enumerate(jo_200)]\n",
        "data += [('Abhijeet', idx, x) for idx, x in enumerate(ao_200)]\n",
        "\n",
        "task = AnnotationTask(data=data)\n",
        "\n",
        "print('Observed Agreement', task.Ao('Jon', 'Abhijeet'))\n",
        "print('Kappa score', task.kappa())\n",
        "print('Multi Kappa score', task.multi_kappa())\n",
        "print('Krippendorf Alpha', task.alpha())"
      ],
      "metadata": {
        "id": "mniXCo51LcCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Scores between Ahbijeet and Omar')\n",
        "data = []\n",
        "data += [('Omar', idx, x) for idx, x in enumerate(oo_200)]\n",
        "data += [('Abhijeet', idx, x) for idx, x in enumerate(ao_200)]\n",
        "\n",
        "task = AnnotationTask(data=data)\n",
        "\n",
        "print('Observed Agreement', task.Ao('Abhijeet', 'Omar'))\n",
        "print('Kappa score', task.kappa())\n",
        "print('Multi Kappa score', task.multi_kappa())\n",
        "print('Krippendorf Alpha', task.alpha())"
      ],
      "metadata": {
        "id": "44tsMXXqLcFT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}